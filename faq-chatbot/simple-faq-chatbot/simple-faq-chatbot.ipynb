{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I apply to HKU through JUPAS scheme?</td>\n",
       "      <td>We welcome your application to HKU through the...</td>\n",
       "      <td>HKDSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the common mistakes as a JUPAS applic...</td>\n",
       "      <td>Students should not forget that in addition to...</td>\n",
       "      <td>HKDSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I apply to HKU as a HKDSE repeater?</td>\n",
       "      <td>All students who apply to HKU on the basis of ...</td>\n",
       "      <td>HKDSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the minimum university entrance requi...</td>\n",
       "      <td>To have your application considered for admiss...</td>\n",
       "      <td>HKDSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How is the admission score calculated?</td>\n",
       "      <td>Starting from the academic year 2020/2021, HKU...</td>\n",
       "      <td>HKDSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>I still have other questions regarding the set...</td>\n",
       "      <td>You might try to look at the FAQ compiled by t...</td>\n",
       "      <td>AAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Are there scholarships that accept application...</td>\n",
       "      <td>Please visit the website of the Scholarships O...</td>\n",
       "      <td>AAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>When and how do I apply for leave of absence?</td>\n",
       "      <td>You need to apply for leave of absence if you ...</td>\n",
       "      <td>AAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>What is plagiarism and what happens if I am fo...</td>\n",
       "      <td>To put it simply, plagiarism is defined as the...</td>\n",
       "      <td>AAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>I have a question that isn’t answered here! Wh...</td>\n",
       "      <td>If you need further advice on some other study...</td>\n",
       "      <td>AAO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Question  \\\n",
       "0          How do I apply to HKU through JUPAS scheme?   \n",
       "1    What are the common mistakes as a JUPAS applic...   \n",
       "2          How can I apply to HKU as a HKDSE repeater?   \n",
       "3    What are the minimum university entrance requi...   \n",
       "4               How is the admission score calculated?   \n",
       "..                                                 ...   \n",
       "170  I still have other questions regarding the set...   \n",
       "171  Are there scholarships that accept application...   \n",
       "172      When and how do I apply for leave of absence?   \n",
       "173  What is plagiarism and what happens if I am fo...   \n",
       "174  I have a question that isn’t answered here! Wh...   \n",
       "\n",
       "                                                Answer   Type  \n",
       "0    We welcome your application to HKU through the...  HKDSE  \n",
       "1    Students should not forget that in addition to...  HKDSE  \n",
       "2    All students who apply to HKU on the basis of ...  HKDSE  \n",
       "3    To have your application considered for admiss...  HKDSE  \n",
       "4    Starting from the academic year 2020/2021, HKU...  HKDSE  \n",
       "..                                                 ...    ...  \n",
       "170  You might try to look at the FAQ compiled by t...    AAO  \n",
       "171  Please visit the website of the Scholarships O...    AAO  \n",
       "172  You need to apply for leave of absence if you ...    AAO  \n",
       "173  To put it simply, plagiarism is defined as the...    AAO  \n",
       "174  If you need further advice on some other study...    AAO  \n",
       "\n",
       "[175 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare internal FAQ dataset\n",
    "df_faq = pd.read_excel('faq-data/df_undergrad_faq.xlsx')\n",
    "\n",
    "df_temp = pd.read_csv('faq-data/df_6901_faq.csv', index_col=0)\n",
    "df_temp['Type'] = 'BSc 6901'\n",
    "df_faq = df_faq.append(df_temp)\n",
    "\n",
    "df_temp = pd.read_excel('faq-data/df_basc_faq.xlsx')\n",
    "df_temp['Type'] = 'BASc'\n",
    "df_faq = df_faq.append(df_temp)\n",
    "\n",
    "df_temp = pd.read_csv('faq-data/df_aao_faq.csv', index_col=0)\n",
    "df_temp['Type'] = 'AAO'\n",
    "df_faq = df_faq.append(df_temp)\n",
    "\n",
    "df_faq.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preproecessed faq dataset\n",
    "df_faq.to_csv('faq-data/df_faq.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kackie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kackie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, sentence):\n",
    "        self.sentence = sentence\n",
    "\n",
    "    # METHOD: preprocess the sentence\n",
    "    # return: list of tokenized words\n",
    "    def preprocess(self, with_stopwords=False):\n",
    "        text = self.sentence\n",
    "\n",
    "        # convert text to lower case\n",
    "        text = text.lower()\n",
    "\n",
    "        # tokenize text into list of words\n",
    "        words = word_tokenize(text)\n",
    "\n",
    "        # remove punctuation\n",
    "        words = [word for word in words if word.isalpha()]\n",
    "\n",
    "        if with_stopwords == False:\n",
    "            # remove stopwords\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            words = [word for word in words if not word in stop_words]\n",
    "\n",
    "        return words\n",
    "        \n",
    "    # METHOD: get word embeddings based on specific model\n",
    "    # return: matrix word embeddings\n",
    "    def get_vector(self, model, with_stopwords=False):\n",
    "        return np.sum(np.array([model[i] for i in self.preprocess(with_stopwords=with_stopwords)]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "# HELPER FUNCTION: get similarities of a specific query against all questions in our FAQ database\n",
    "# return: dataframe with new column 'Similarity'\n",
    "def get_similarities(query, df, model, with_stopwords=False):\n",
    "    similarities = []\n",
    "    query = Sentence(query)\n",
    "    for q in df['Question']:\n",
    "        s = Sentence(q)\n",
    "        try:\n",
    "            similarity = 1 - spatial.distance.cosine(\n",
    "                query.get_vector(model, with_stopwords), \n",
    "                s.get_vector(model, with_stopwords)\n",
    "            )\n",
    "            similarities.append(similarity)\n",
    "        except:\n",
    "            similarities.append(0)\n",
    "            continue\n",
    "    df['Similarity'] = similarities\n",
    "    \n",
    "    df = df.sort_values(by='Similarity', ascending=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define any query\n",
    "QUERY = 'I want to apply for a scholarship.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# define GloVe model\n",
    "model_glove = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WITHOUT stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cosine similarity scores for every entry in our FAQ database\n",
    "# WITHOUT stopwords\n",
    "get_similarities(QUERY, df_faq, model_glove, with_stopwords=False).to_csv('model-sample-results/glove-without-stopwords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WITH stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cosine similarity scores for every entry in our FAQ database\n",
    "# WITH stopwords\n",
    "get_similarities(QUERY, df_faq, model_glove, with_stopwords=True).to_csv('model-sample-results/glove-with-stopwords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('DataScience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32d60d92059b3e36b6bd9986edfc808c4ae526b74500509951e82855bb1b814d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
